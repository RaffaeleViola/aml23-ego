{
<<<<<<< HEAD
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started for the AML 2023/2024 Egocentric Vision Project"
   ]
=======
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting started for the AML 2023/2024 Egocentric Vision Project"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EgovisionPolito/aml23-ego/blob/master/colab_runner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Downloading the code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the public repository (or your repository)\n",
        "!git clone https://github.com/EgovisionPolito/aml23-ego.git aml23-ego"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: omegaconf in ./.venv/lib/python3.11/site-packages (2.3.0)\n",
            "Requirement already satisfied: coloredlogs in ./.venv/lib/python3.11/site-packages (15.0.1)\n",
            "Requirement already satisfied: wandb in ./.venv/lib/python3.11/site-packages (0.17.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in ./.venv/lib/python3.11/site-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in ./.venv/lib/python3.11/site-packages (from omegaconf) (6.0.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in ./.venv/lib/python3.11/site-packages (from coloredlogs) (10.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in ./.venv/lib/python3.11/site-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in ./.venv/lib/python3.11/site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in ./.venv/lib/python3.11/site-packages (from wandb) (4.2.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in ./.venv/lib/python3.11/site-packages (from wandb) (4.25.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in ./.venv/lib/python3.11/site-packages (from wandb) (5.9.8)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in ./.venv/lib/python3.11/site-packages (from wandb) (2.1.1)\n",
            "Requirement already satisfied: setproctitle in ./.venv/lib/python3.11/site-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.11/site-packages (from wandb) (65.5.0)\n",
            "Requirement already satisfied: six>=1.4.0 in ./.venv/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.venv/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in ./.venv/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "# Installing missing dependencies\n",
        "!pip install omegaconf coloredlogs wandb"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EPIC-Kitchens-55 dataset\n",
        "\n",
        "**READ carefully!**\n",
        "\n",
        "To develop the project, you need to download the RGB frames for a subset of EPIC-Kitchens-55 (participants P08, P01 and P22) from [here](https://drive.google.com/drive/u/1/folders/1dJOtZ07WovP3YSCRAnU0E4gsfqDzpMVo). \n",
        "\n",
        "You also need to the pretrained checkpoints for each domain from [here](https://politoit-my.sharepoint.com/:f:/g/personal/simone_peirone_polito_it/ErdsZhvmR65Lun5_5O0-l5sBTPjCCZZq2f700Tj_CNzjTQ?e=L1yflf).\n",
        "\n",
        "Add the Google Drive directory containing the dataset to your Google Drive or upload the dataset on your Google Drive to access it from Google Colab.\n",
        "\n",
        "**NOTE**: As the dataset is quite heavy, we stronly suggest you to implement and test all your code on one for the three dataset. Then, once you are sure everything works, repeat the experiments on the remaining two datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Mount google drive \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# Mount google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "cp: /content/drive/MyDrive/AML23/EPIC-Kitchens-55/data/*.tar.gz: No such file or directory\n",
            "ls: ./ek_data/*.tar.gz: No such file or directory\n",
            "tar: Error opening archive: Failed to open './ek_data/*.tar.gz'\n"
          ]
        },
        {
          "ename": "CalledProcessError",
          "evalue": "Command 'b\"\\n# As read and write operations from google drive are slow, we suggest to copy and unzip\\n# the dataset in a local directory on the Colab's machine.\\nmkdir -p ek_data/frames\\n\\n# Copy the *.tar.gz files of Epic-Kitchens\\n# TODO: replace with your path to the dataset\\ncp /content/drive/MyDrive/AML23/EPIC-Kitchens-55/data/*.tar.gz ./ek_data\\n# Untar\\nfor file in ./ek_data/*.tar.gz; do\\n  fn=$(basename $file)\\n  fn=${fn/.tar.gz/}\\n  ls -lah $file\\n  mkdir -p ek_data/frames/$fn\\n  tar xf $file --directory=ek_data/frames/$fn\\ndone\\n\"' returned non-zero exit status 1.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# As read and write operations from google drive are slow, we suggest to copy and unzip\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# the dataset in a local directory on the Colab\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms machine.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mmkdir -p ek_data/frames\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Copy the *.tar.gz files of Epic-Kitchens\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# TODO: replace with your path to the dataset\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mcp /content/drive/MyDrive/AML23/EPIC-Kitchens-55/data/*.tar.gz ./ek_data\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Untar\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfor file in ./ek_data/*.tar.gz; do\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  fn=$(basename $file)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  fn=$\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43mfn/.tar.gz/}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  ls -lah $file\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  mkdir -p ek_data/frames/$fn\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  tar xf $file --directory=ek_data/frames/$fn\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mdone\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/aml23-ego/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2541\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2540\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2541\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2543\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2545\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
            "File \u001b[0;32m~/Desktop/aml23-ego/.venv/lib/python3.11/site-packages/IPython/core/magics/script.py:155\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/aml23-ego/.venv/lib/python3.11/site-packages/IPython/core/magics/script.py:315\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b\"\\n# As read and write operations from google drive are slow, we suggest to copy and unzip\\n# the dataset in a local directory on the Colab's machine.\\nmkdir -p ek_data/frames\\n\\n# Copy the *.tar.gz files of Epic-Kitchens\\n# TODO: replace with your path to the dataset\\ncp /content/drive/MyDrive/AML23/EPIC-Kitchens-55/data/*.tar.gz ./ek_data\\n# Untar\\nfor file in ./ek_data/*.tar.gz; do\\n  fn=$(basename $file)\\n  fn=${fn/.tar.gz/}\\n  ls -lah $file\\n  mkdir -p ek_data/frames/$fn\\n  tar xf $file --directory=ek_data/frames/$fn\\ndone\\n\"' returned non-zero exit status 1."
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "# As read and write operations from google drive are slow, we suggest to copy and unzip\n",
        "# the dataset in a local directory on the Colab's machine.\n",
        "mkdir -p ek_data/frames\n",
        "\n",
        "# Copy the *.tar.gz files of Epic-Kitchens\n",
        "# TODO: replace with your path to the dataset\n",
        "cp /content/drive/MyDrive/AML23/EPIC-Kitchens-55/data/*.tar.gz ./ek_data\n",
        "# Untar\n",
        "for file in ./ek_data/*.tar.gz; do\n",
        "  fn=$(basename $file)\n",
        "  fn=${fn/.tar.gz/}\n",
        "  ls -lah $file\n",
        "  mkdir -p ek_data/frames/$fn\n",
        "  tar xf $file --directory=ek_data/frames/$fn\n",
        "done"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Features extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88YghJyXhbfS"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# Replace the following path with the path of your codebase\n",
        "cd aml23-ego \n",
        "\n",
        "python save_feat.py name=change_me \\\n",
        "  config=configs/I3D_save_feat.yaml \\\n",
        "  dataset.shift=D1-D1 \\\n",
        "  dataset.RGB.data_path=../ek_data/frames \n",
        "\n",
        "# If everything is working, you should expect an error message telling you to implement the '_get_val_indices' method in the dataset class.\n",
        "# Once you have implemented it, you should run the script for the train and test split of the dataset to extract the features."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMA44pwS84HIKtaEclSmH2W",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "aml22",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "2fc1f0eeae38a5df67b0f713e03196095ce1bfa55aa551576e8e58c2ba904c5a"
      }
    }
>>>>>>> b2f6c1292a809c6035d72ab90d5da340f9108111
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/EgovisionPolito/aml23-ego/blob/master/colab_runner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the public repository (or your repository)\n",
    "!git clone https://github.com/EgovisionPolito/aml23-ego.git aml23-ego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing missing dependencies\n",
    "!pip install omegaconf coloredlogs wandb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPIC-Kitchens-55 dataset\n",
    "\n",
    "**READ carefully!**\n",
    "\n",
    "To develop the project, you need to download the RGB frames for a subset of EPIC-Kitchens-55 (participants P08, P01 and P22) from [here](https://drive.google.com/drive/u/1/folders/1dJOtZ07WovP3YSCRAnU0E4gsfqDzpMVo). \n",
    "\n",
    "You also need to the pretrained checkpoints for each domain from [here](https://politoit-my.sharepoint.com/:f:/g/personal/simone_peirone_polito_it/ErdsZhvmR65Lun5_5O0-l5sBTPjCCZZq2f700Tj_CNzjTQ?e=L1yflf).\n",
    "\n",
    "Add the Google Drive directory containing the dataset to your Google Drive or upload the dataset on your Google Drive to access it from Google Colab.\n",
    "\n",
    "**NOTE**: As the dataset is quite heavy, we stronly suggest you to implement and test all your code on one for the three dataset. Then, once you are sure everything works, repeat the experiments on the remaining two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/76/5ysc1qcx51g2dmdfhmc1f3fw0000gn/T/ipykernel_24303/859467756.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Mount google drive\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mgoogle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolab\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mdrive\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mdrive\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmount\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'/content/drive'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Mount google drive \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: cp [-R [-H | -L | -P]] [-fi | -n] [-aclpSsvXx] source_file target_file\n",
      "       cp [-R [-H | -L | -P]] [-fi | -n] [-aclpSsvXx] source_file ... target_directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--@ 1 raffaeleviola  staff   122M Dec 31  1979 ./ek_data/P08_02.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   168M Dec 31  1979 ./ek_data/P08_03.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   237M Dec 31  1979 ./ek_data/P08_04.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   584M Dec 31  1979 ./ek_data/P08_06.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff    24M Dec 31  1979 ./ek_data/P08_07.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   161M Dec 31  1979 ./ek_data/P08_08.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   821M Dec 31  1979 ./ek_data/P08_09.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   290M Dec 31  1979 ./ek_data/P08_10.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   206M Dec 31  1979 ./ek_data/P08_11.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff    27M Dec 31  1979 ./ek_data/P08_12.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff    21M Dec 31  1979 ./ek_data/P08_13.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   170M Dec 31  1979 ./ek_data/P08_14.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   664M Dec 31  1979 ./ek_data/P08_15.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   785M Dec 31  1979 ./ek_data/P08_16.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   796M Dec 31  1979 ./ek_data/P08_17.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   577M Dec 31  1979 ./ek_data/P08_18.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   151M Dec 31  1979 ./ek_data/P08_19.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   244M Dec 31  1979 ./ek_data/P08_20.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   1.8G Dec 31  1979 ./ek_data/P08_21.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   147M Dec 31  1979 ./ek_data/P08_22.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   846M Dec 31  1979 ./ek_data/P08_24.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff    29M Dec 31  1979 ./ek_data/P08_25.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   497M Dec 31  1979 ./ek_data/P08_26.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff   218M Dec 31  1979 ./ek_data/P08_27.zip\n",
      "-rw-r--r--@ 1 raffaeleviola  staff    34M Dec 31  1979 ./ek_data/P08_28.zip\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# As read and write operations from google drive are slow, we suggest to copy and unzip\n",
    "# the dataset in a local directory on the Colab's machine.\n",
    "mkdir -p ek_data/frames\n",
    "\n",
    "# Copy the *.tar.gz files of Epic-Kitchens\n",
    "# TODO: replace with your path to the dataset\n",
    "# cp /content/drive/MyDrive/AML23/EPIC-Kitchens-55/data/*.tar.gz ./ek_data\n",
    "cp /Users/raffaeleviola/Documents/AMLProject/EK_Data\n",
    "# Untar\n",
    "for file in ./ek_data/*.zip; do\n",
    "  fn=$(basename $file)\n",
    "  fn=${fn/.zip/}\n",
    "  ls -lah $file\n",
    "  tar xf $file --directory=ek_data/frames\n",
    "done"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "88YghJyXhbfS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/raffaeleviola/Documents/AMLProject/save_feat.py\", line 2, in <module>\n",
      "    from utils.logger import logger\n",
      "  File \"/Users/raffaeleviola/Documents/AMLProject/utils/logger.py\", line 2, in <module>\n",
      "    import coloredlogs\n",
      "ModuleNotFoundError: No module named 'coloredlogs'\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b\"\\n# Replace the following path with the path of your codebase\\n# cd aml23-ego\\n\\npython save_feat.py name=change_me \\\\\\n  config=configs/I3D_save_feat.yaml \\\\\\n  dataset.shift=D1-D1 \\\\\\n  dataset.RGB.data_path=../ek_data/frames \\n\\n# If everything is working, you should expect an error message telling you to implement the '_get_val_indices' method in the dataset class.\\n# Once you have implemented it, you should run the script for the train and test split of the dataset to extract the features.\\n\"' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCalledProcessError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_cell_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbash\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m# Replace the following path with the path of your codebase\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m# cd aml23-ego\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mpython save_feat.py name=change_me \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m  config=configs/I3D_save_feat.yaml \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m  dataset.shift=D1-D1 \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m  dataset.RGB.data_path=../ek_data/frames \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m# If everything is working, you should expect an error message telling you to implement the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_get_val_indices\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m method in the dataset class.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m# Once you have implemented it, you should run the script for the train and test split of the dataset to extract the features.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2517\u001B[0m, in \u001B[0;36mInteractiveShell.run_cell_magic\u001B[0;34m(self, magic_name, line, cell)\u001B[0m\n\u001B[1;32m   2515\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[1;32m   2516\u001B[0m     args \u001B[38;5;241m=\u001B[39m (magic_arg_s, cell)\n\u001B[0;32m-> 2517\u001B[0m     result \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   2519\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[1;32m   2520\u001B[0m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[1;32m   2521\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[1;32m   2522\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/IPython/core/magics/script.py:154\u001B[0m, in \u001B[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001B[0;34m(line, cell)\u001B[0m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    153\u001B[0m     line \u001B[38;5;241m=\u001B[39m script\n\u001B[0;32m--> 154\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshebang(line, cell)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/IPython/core/magics/script.py:314\u001B[0m, in \u001B[0;36mScriptMagics.shebang\u001B[0;34m(self, line, cell)\u001B[0m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39mraise_error \u001B[38;5;129;01mand\u001B[39;00m p\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    310\u001B[0m     \u001B[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001B[39;00m\n\u001B[1;32m    311\u001B[0m     \u001B[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001B[39;00m\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001B[39;00m\n\u001B[1;32m    313\u001B[0m     rc \u001B[38;5;241m=\u001B[39m p\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m9\u001B[39m\n\u001B[0;32m--> 314\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CalledProcessError(rc, cell)\n",
      "\u001B[0;31mCalledProcessError\u001B[0m: Command 'b\"\\n# Replace the following path with the path of your codebase\\n# cd aml23-ego\\n\\npython save_feat.py name=change_me \\\\\\n  config=configs/I3D_save_feat.yaml \\\\\\n  dataset.shift=D1-D1 \\\\\\n  dataset.RGB.data_path=../ek_data/frames \\n\\n# If everything is working, you should expect an error message telling you to implement the '_get_val_indices' method in the dataset class.\\n# Once you have implemented it, you should run the script for the train and test split of the dataset to extract the features.\\n\"' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Replace the following path with the path of your codebase\n",
    "# cd aml23-ego\n",
    "\n",
    "python save_feat.py name=change_me \\\n",
    "  config=configs/I3D_save_feat.yaml \\\n",
    "  dataset.shift=D1-D1 \\\n",
    "  dataset.RGB.data_path=../ek_data/frames \n",
    "\n",
    "# If everything is working, you should expect an error message telling you to implement the '_get_val_indices' method in the dataset class.\n",
    "# Once you have implemented it, you should run the script for the train and test split of the dataset to extract the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMA44pwS84HIKtaEclSmH2W",
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "aml22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2fc1f0eeae38a5df67b0f713e03196095ce1bfa55aa551576e8e58c2ba904c5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

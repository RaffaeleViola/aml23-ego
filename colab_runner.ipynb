{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting started for the AML 2023/2024 Egocentric Vision Project"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EgovisionPolito/aml23-ego/blob/master/colab_runner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Downloading the code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the public repository (or your repository)\n",
        "!git clone --branch Nunzio https://github.com/RaffaeleViola/aml23-ego.git aml23-ego1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting omegaconf\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.17.7-py3-none-win_amd64.whl.metadata (10 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting PyYAML>=5.1.0 (from omegaconf)\n",
            "  Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting click!=8.0.0,>=7.1 (from wandb)\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in c:\\users\\nunzi\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (4.2.2)\n",
            "Collecting protobuf!=4.21.0,<6,>=3.19.0 (from wandb)\n",
            "  Downloading protobuf-5.27.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\nunzi\\appdata\\roaming\\python\\python312\\site-packages (from wandb) (6.0.0)\n",
            "Collecting requests<3,>=2.0.0 (from wandb)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp312-cp312-win_amd64.whl.metadata (10 kB)\n",
            "Collecting setuptools (from wandb)\n",
            "  Using cached setuptools-73.0.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\nunzi\\appdata\\roaming\\python\\python312\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
            "Requirement already satisfied: six>=1.4.0 in c:\\users\\nunzi\\appdata\\roaming\\python\\python312\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs)\n",
            "  Downloading pyreadline3-3.4.1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.0.0->wandb)\n",
            "  Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.0.0->wandb)\n",
            "  Downloading idna-3.8-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.0.0->wandb)\n",
            "  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.0.0->wandb)\n",
            "  Downloading certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Downloading wandb-0.17.7-py3-none-win_amd64.whl (6.5 MB)\n",
            "   ---------------------------------------- 0.0/6.5 MB ? eta -:--:--\n",
            "   -------------------------------- ------- 5.2/6.5 MB 29.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 6.5/6.5 MB 25.0 MB/s eta 0:00:00\n",
            "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Downloading protobuf-5.27.3-cp310-abi3-win_amd64.whl (426 kB)\n",
            "Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
            "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n",
            "Downloading setproctitle-1.3.3-cp312-cp312-win_amd64.whl (11 kB)\n",
            "Using cached setuptools-73.0.1-py3-none-any.whl (2.3 MB)\n",
            "Downloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
            "Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "Downloading idna-3.8-py3-none-any.whl (66 kB)\n",
            "Downloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
            "Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
            "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (pyproject.toml): started\n",
            "  Building wheel for antlr4-python3-runtime (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144578 sha256=022d2db5ad9dfc6660af0b1472b5ffec78bbe2a0a0febd39d6671300edb59b99\n",
            "  Stored in directory: c:\\users\\nunzi\\appdata\\local\\pip\\cache\\wheels\\1f\\be\\48\\13754633f1d08d1fbfc60d5e80ae1e5d7329500477685286cd\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: pyreadline3, antlr4-python3-runtime, urllib3, smmap, setuptools, setproctitle, PyYAML, protobuf, idna, humanfriendly, docker-pycreds, click, charset-normalizer, certifi, sentry-sdk, requests, omegaconf, gitdb, coloredlogs, gitpython, wandb\n",
            "Successfully installed PyYAML-6.0.2 antlr4-python3-runtime-4.9.3 certifi-2024.7.4 charset-normalizer-3.3.2 click-8.1.7 coloredlogs-15.0.1 docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 humanfriendly-10.0 idna-3.8 omegaconf-2.3.0 protobuf-5.27.3 pyreadline3-3.4.1 requests-2.32.3 sentry-sdk-2.13.0 setproctitle-1.3.3 setuptools-73.0.1 smmap-5.0.1 urllib3-2.2.2 wandb-0.17.7\n"
          ]
        }
      ],
      "source": [
        "# Installing missing dependencies\n",
        "!pip install omegaconf coloredlogs wandb"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EPIC-Kitchens-55 dataset\n",
        "\n",
        "**READ carefully!**\n",
        "\n",
        "To develop the project, you need to download the RGB frames for a subset of EPIC-Kitchens-55 (participants P08, P01 and P22) from [here](https://drive.google.com/drive/u/1/folders/1dJOtZ07WovP3YSCRAnU0E4gsfqDzpMVo). \n",
        "\n",
        "You also need to the pretrained checkpoints for each domain from [here](https://politoit-my.sharepoint.com/:f:/g/personal/simone_peirone_polito_it/ErdsZhvmR65Lun5_5O0-l5sBTPjCCZZq2f700Tj_CNzjTQ?e=L1yflf).\n",
        "\n",
        "Add the Google Drive directory containing the dataset to your Google Drive or upload the dataset on your Google Drive to access it from Google Colab.\n",
        "\n",
        "**NOTE**: As the dataset is quite heavy, we stronly suggest you to implement and test all your code on one for the three dataset. Then, once you are sure everything works, repeat the experiments on the remaining two datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# As read and write operations from google drive are slow, we suggest to copy and unzip\n",
        "# the dataset in a local directory on the Colab's machine.\n",
        "mkdir -p ek_data/frames\n",
        "\n",
        "# Copy the *.zip files of Epic-Kitchens\n",
        "cp /content/drive/MyDrive/epic_kitchens_reduced/P08_0*.zip ./ek_data\n",
        "# unzip\n",
        "for file in ./ek_data/*.zip; do\n",
        "  fn=$(basename $file)\n",
        "  fn=${fn/.zip}\n",
        "  ls -lah $file\n",
        "  echo \"Processing $file\"\n",
        "  mkdir -p ek_data/frames/$fn\n",
        "  unzip $file -d ek_data/frames/$fn\n",
        "done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Create directory for extracted frames\n",
        "os.makedirs('ek_data/frames', exist_ok=True)\n",
        "\n",
        "# Copy and unzip files from source directory\n",
        "source_dir = r'Epich_kitchens_reduced'\n",
        "target_dir = r'ek_data'\n",
        "\n",
        "# Unzipping the files\n",
        "for file in os.listdir(source_dir):\n",
        "    if file.endswith('.zip'):\n",
        "        file_path = os.path.join(source_dir, file)\n",
        "        print(f\"Processing {file_path}\")\n",
        "        \n",
        "        # Create a folder to extract the content\n",
        "        folder_name = file.replace('.zip', '')\n",
        "        output_dir = os.path.join(target_dir, 'frames', folder_name)\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        \n",
        "        # Extract the zip file\n",
        "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(output_dir)\n",
        "\n",
        "        print(f\"Finished extracting {file_path}\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Features extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88YghJyXhbfS"
      },
      "outputs": [],
      "source": [
        "!python save_feat.py name=change_me config=configs/I3D_save_feat.yaml dataset.shift=D1-D1 dataset.RGB.data_path=.\\ek_data\\frames\n",
        "\n",
        "# If everything is working, you should expect an error message telling you to implement the '_get_val_indices' method in the dataset class.\n",
        "# Once you have implemented it, you should run the script for the train and test split of the dataset to extract the features."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMA44pwS84HIKtaEclSmH2W",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "aml22",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "2fc1f0eeae38a5df67b0f713e03196095ce1bfa55aa551576e8e58c2ba904c5a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
